---
title: "**Approximation of the distribution function of $N(0,1)$**"
author: "Carolyn-Yu"
date: "2020/03/24"
output:
  html_document: default
  pdf_document: default
---

# abstract 

This report use the process of repeated random sampling to estimate the approximation of the distribution fuction of $N(0,1)$ by the Monte Carlo methods.  
**keywords:** Monte Carlo methods, R Markdown, Standard Normal Distribution

# 1. Introduction

Monte Carlo methods are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. In Statistics, Monte Carlo experimentation can use simulated random numbers to make numerical estimations of unknown parameters.
In this report, I consider approximation of the distribution function of $N(0,1)$ by the the Monte Carlo methods.

# 2. Math Equations

I'd like to show you some math equations that I will use in this report.  

a. the distribution function of $N(0,1)$:  

\begin{equation}
\Phi(t) = \int_{-\infty}^t \frac{1}{\sqrt{2\pi}} e^{\frac{-y^2}{2}} dy
\end{equation}  

b. the Monte Carlo methods:  

\begin{equation}
\hat\Phi(t) = \frac{1}{n} \sum_{i=1}^n I(X_i \le t),
\end{equation}  

where $X_i$'s are a random sample from $N(0, 1)$, and $I(\cdot)$ is the indicator function.  

# 3. Positive Analysis  

This experiment chooses some random samples of different sizes ($n\in\{10^2, 10^3, 10^4\}$) and some kinds of t 
($t\in\{0.0,0.67,0.84,1.28,1.65,2.32,2.58,3.09,3.72\}$) to estimate the approximation of the distribution function of $N(0,1)$ by R statistical software.

## 3.1 The true value for comparison

Firstly, a table is produced which includes the true value for comparison of only one experiment. 

```{r echo=FALSE}
t=c(0,0.67,0.84,1.28,1.65,2.32,2.58,3.09,3.72)
n=c(10^2,10^3,10^3)
p=matrix(0,nrow=9,ncol=3)
for (i in 1:9)
  for(j in 1:3){
    num=rnorm(n[j],0,1)
    p[i,j]=mean(num<t[i])
    }
rownames(p)<-t
colnames(p)<-n
true_value<-c(pnorm(0),pnorm(0.67),pnorm(0.84),pnorm(1.28),pnorm(1.65),
           pnorm(2.32),pnorm(2.58),pnorm(3.09),pnorm(3.72))
p<-cbind(p,true_value)
p<-round(p,digits=3)
library(knitr)
library(magrittr)
library(kableExtra)
library(callr)
library(webshot)
kable(p, booktabs=TRUE, caption='the True Value for Comparison') %>%
kable_styling(bootstrap_options = "striped",full_width = T) %>% 
column_spec(1,bold=T)
```

## 3.2 Repeat the experiment 100 times

To better compare the errors between the results of Monte Carlo simulation and the true value, the best way is to repeat the experiment 100 times.  

### 3.2.1 the box plot of the 100 approximation errors (n=100)    
.  
```{r echo=FALSE}
x=pnorm( c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72), mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE )
t=c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72)

n=10^2
z=matrix(0,100,9)
w=matrix(0,9,n)

for(p in 1:100)
{ y=c(rnorm(n,mean=0,sd=1))
  for(k in 1:9)
  {
   for(j in 1:n)
  {w[k,j]=sign(y[j]<=t[k])}
z[p,k]=sum(w[k,])/n}}
z=as.data.frame(z)
r=c(z$V1,z$V2,z$V3,z$V4,z$V5,z$V6,z$V7,z$V8,z$V9)
e=c(rep(0.0,100),rep(0.67,100),rep(0.84,100),rep(1.28,100),rep(1.65,100),rep(2.32,100),rep(2.58,100),rep(3.09,100),rep(3.72,100))
q=data.frame(T=rep(0,100),X=0)
for(s in 1:900)
{q[s,2]=r[s]}
for(s in 1:900)
{q[s,1]=e[s]}

for(a in 1:100)
 { q[a,2]=q[a,2]-x[1]
 q[a+100,2]=q[a+100,2]-x[2]
 q[a+200,2]=q[a+200,2]-x[3]
 q[a+300,2]=q[a+300,2]-x[4]
 q[a+400,2]=q[a+400,2]-x[5]
 q[a+500,2]=q[a+500,2]-x[6]
 q[a+600,2]=q[a+600,2]-x[7]
 q[a+700,2]=q[a+700,2]-x[8]
 q[a+800,2]=q[a+800,2]-x[9]}
library(ggplot2)
ggplot(q,aes(T,X,group=T)) + 
  geom_boxplot() + 
  scale_x_continuous(breaks=c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72)) + 
  labs(title="Figure 1: the box plot of the 100 approximation errors (n=10^2)",y="error",
       x="t") + 
  theme(plot.title=element_text(size=9,hjust=0.3))  
```  

### 3.2.2 the box plot of the 100 approximation errors (n=1000)  
.  
```{r echo=FALSE}
x=pnorm( c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72), mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE )
t=c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72)

n=10^3
z=matrix(0,100,9)
w=matrix(0,9,n)

for(p in 1:100)
{ y=c(rnorm(n,mean=0,sd=1))
  for(k in 1:9)
  {
   for(j in 1:n)
  {w[k,j]=sign(y[j]<=t[k])}
z[p,k]=sum(w[k,])/n}}
z=as.data.frame(z)
r=c(z$V1,z$V2,z$V3,z$V4,z$V5,z$V6,z$V7,z$V8,z$V9)
e=c(rep(0.0,100),rep(0.67,100),rep(0.84,100),rep(1.28,100),rep(1.65,100),rep(2.32,100),rep(2.58,100),rep(3.09,100),rep(3.72,100))
q=data.frame(T=rep(0,100),X=0)
for(s in 1:900)
{q[s,2]=r[s]}
for(s in 1:900)
{q[s,1]=e[s]}

for(a in 1:100)
 { q[a,2]=q[a,2]-x[1]
 q[a+100,2]=q[a+100,2]-x[2]
 q[a+200,2]=q[a+200,2]-x[3]
 q[a+300,2]=q[a+300,2]-x[4]
 q[a+400,2]=q[a+400,2]-x[5]
 q[a+500,2]=q[a+500,2]-x[6]
 q[a+600,2]=q[a+600,2]-x[7]
 q[a+700,2]=q[a+700,2]-x[8]
 q[a+800,2]=q[a+800,2]-x[9]}
library(ggplot2)
ggplot(q,aes(T,X,group=T)) + 
  geom_boxplot() + 
  scale_x_continuous(breaks=c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72)) + 
  labs(title="Figure 2: the box plot of the 100 approximation errors (n=10^3)",y="error",
       x="t") + 
  theme(plot.title=element_text(size=9,hjust=0.3))  
```  

### 3.2.3 the box plot of the 100 approximation errors (n=10000)
.  
```{r echo=FALSE}
x=pnorm( c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72), mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE )
t=c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72)

n=10^4
z=matrix(0,100,9)
w=matrix(0,9,n)

for(p in 1:100)
{ y=c(rnorm(n,mean=0,sd=1))
  for(k in 1:9)
  {
   for(j in 1:n)
  {w[k,j]=sign(y[j]<=t[k])}
z[p,k]=sum(w[k,])/n}}
z=as.data.frame(z)
r=c(z$V1,z$V2,z$V3,z$V4,z$V5,z$V6,z$V7,z$V8,z$V9)
e=c(rep(0.0,100),rep(0.67,100),rep(0.84,100),rep(1.28,100),rep(1.65,100),rep(2.32,100),rep(2.58,100),rep(3.09,100),rep(3.72,100))
q=data.frame(T=rep(0,100),X=0)
for(s in 1:900)
{q[s,2]=r[s]}
for(s in 1:900)
{q[s,1]=e[s]}

for(a in 1:100)
 { q[a,2]=q[a,2]-x[1]
 q[a+100,2]=q[a+100,2]-x[2]
 q[a+200,2]=q[a+200,2]-x[3]
 q[a+300,2]=q[a+300,2]-x[4]
 q[a+400,2]=q[a+400,2]-x[5]
 q[a+500,2]=q[a+500,2]-x[6]
 q[a+600,2]=q[a+600,2]-x[7]
 q[a+700,2]=q[a+700,2]-x[8]
 q[a+800,2]=q[a+800,2]-x[9]}
library(ggplot2)
ggplot(data=q,aes(x=T,y=X,group=T)) + 
  geom_boxplot() + 
  scale_x_continuous(breaks=c(0.0,0.67, 0.84,1.28,1.65,2.32,2.58,3.09,3.72)) + 
  labs(title="Figure 1: the box plot of the 100 approximation errors (n=10^4)",y="error",
       x="t") + 
  theme(plot.title=element_text(size=9,hjust=0.3))
```  

# 4. Conclusion
In conclusion, according to the above results, I find that the error used to compare the result of Monte Carlo simulation and the true value decreases as the number of sample increases. At the same time, with the increase of the number of samples, the extreme value decreases gradually.